{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"mistral-nemo:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"아래 코드는 처음 data를 vector db에 저장할 때\"\"\"\n",
    "# import os\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# from langchain_community.document_loaders import DirectoryLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# loader = DirectoryLoader(path='test_con/input/news', glob='*.txt')\n",
    "\n",
    "# data = loader.load()\n",
    "\n",
    "# len(data)\n",
    "# # 문서를 문장으로 분리\n",
    "# ## 청크 크기 500, 각 청크의 50자씩 겹치도록 청크를 나눈다\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=500,\n",
    "#     chunk_overlap=50,\n",
    "# )\n",
    "# docs = text_splitter.split_documents(data)\n",
    "\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# # 문장을 임베딩으로 변환하고 벡터 저장소에 저장\n",
    "# embeddings = HuggingFaceEmbeddings(\n",
    "#     model_name='BAAI/bge-m3',\n",
    "#     #model_kwargs={'device':'cpu'},\n",
    "#     model_kwargs={'device':'cuda'},\n",
    "#     encode_kwargs={'normalize_embeddings':True},\n",
    "# )\n",
    "\n",
    "# # 벡터 저장소 생성\n",
    "# from langchain.vectorstores import Chroma\n",
    "# vectorstore = Chroma.from_documents(docs, embeddings)\n",
    "\n",
    "\n",
    "# # 벡터 저장소 경로 설정\n",
    "# ## 현재 경로에 'vectorstore' 경로 생성\n",
    "# vectorstore_path = 'vectorstore'\n",
    "# os.makedirs(vectorstore_path, exist_ok=True)\n",
    "\n",
    "# # 벡터 저장소 생성 및 저장\n",
    "# vectorstore = Chroma.from_documents(docs, embeddings, persist_directory=vectorstore_path)\n",
    "# # 벡터스토어 데이터를 디스크에 저장\n",
    "# vectorstore.persist()\n",
    "# print(\"Vectorstore created and persisted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# 기존에 저장한 벡터 저장소 경로 설정\n",
    "vectorstore_path = 'vectorstore'\n",
    "\n",
    "# Chroma 벡터 저장소 불러오기\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=vectorstore_path,\n",
    "    embedding_function=HuggingFaceEmbeddings(\n",
    "        model_name='BAAI/bge-m3',\n",
    "        model_kwargs={'device':'cuda'},\n",
    "        encode_kwargs={'normalize_embeddings':True},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "# 프롬프트 템플릿\n",
    "template = '''모든 응답은 정확한 정보만을 바탕으로 제공되어야 합니다. \n",
    "응답에 필요한 정보가 벡터 저장소에 없을 경우, \"모릅니다.\"라고 응답하세요.\n",
    "한국어로 포괄적이고 명확한 답변을 제공해 주세요.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join([d.page_content for d in docs])\n",
    "\n",
    "# RAG Chain 연결\n",
    "rag_chain = (\n",
    "    {'context': retriever | format_docs, 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벤치마킹에 사용할 질문 리스트\n",
    "questions = [\n",
    "    \"주식 부정거래 의혹에 대한 뉴스기사에서 누가 보석으로 풀려났나?\",\n",
    "    \"지방선거 구도를 다루는 기사에서 어떤 내용을 다루나?\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벤치마킹 실행\n",
    "results = []\n",
    "for query in questions:\n",
    "    answer = rag_chain.invoke(query)\n",
    "    results.append((query, answer))\n",
    "    print(\"Query:\", query)\n",
    "    print(\"Answer:\", answer)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장 (옵션)\n",
    "with open(\"benchmark_results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for query, answer in results:\n",
    "        f.write(f\"Query: {query}\\nAnswer: {answer}\\n{'-'*50}\\n\")\n",
    "\n",
    "print(\"벤치마킹이 완료되었습니다. 결과가 'benchmark_results_token500_50.txt'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: “코로나19 동안 대한민국의 정치적 결정에 어떤 변화가 있었는가?”\n",
      "Answer: \"코로나19 기간 동안 대한민국의 정치적 결정을 볼 때, 정부는 사회적 거리두기 단계 조정 방안을 논의하고 결정해야 한다고 시사했으며, 이행과 실천, 그리고 현장의 수용성 등을 고려해 불합리하거나 실효성이 없는 조치는 과감히 수정하겠다고 강조했습니다. 또한 국민들의 인권침해 소지가 있는 무리한 방역대책을 결과적으로 사회 불안을 증폭시킨다는 점을 인식하고 있습니다.\"\n"
     ]
    }
   ],
   "source": [
    "# Chain 실행\n",
    "query = \"“코로나19 동안 대한민국의 정치적 결정에 어떤 변화가 있었는가?”\"\n",
    "answer = rag_chain.invoke(query)\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"Answer:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
